# H∆∞·ªõng d·∫´n Setup Face Recognition v·ªõi Custom Dev Client

## üéØ M·ª•c ti√™u
T√≠ch h·ª£p Face Recognition v√†o app ch·∫•m c√¥ng m√† KH√îNG c·∫ßn eject kh·ªèi Expo, s·ª≠ d·ª•ng Custom Dev Client.

## üì¶ C√†i ƒë·∫∑t c√°c package c·∫ßn thi·∫øt

```bash
cd mobileApp

# C√†i ƒë·∫∑t EAS CLI
npm install -g eas-cli

# Login v√†o Expo
eas login

# C√†i ƒë·∫∑t c√°c dependencies cho face recognition
npx expo install expo-dev-client
npm install react-native-vision-camera
npm install vision-camera-face-detector@1.9.1
npm install @react-native-ml-kit/face-detection
```

## üèóÔ∏è Build Custom Dev Client

### Cho Android:
```bash
# Build development client cho Android
eas build --profile development --platform android

# Ho·∫∑c build local (nhanh h∆°n)
npx expo run:android
```

### Cho iOS:
```bash
# Build development client cho iOS  
eas build --profile development --platform ios

# Ho·∫∑c build local
npx expo run:ios
```

## üìù C·∫≠p nh·∫≠t code

### 1. T·∫°o Face Detection Service
File: `services/faceDetectionService.js`

```javascript
import FaceDetector from '@react-native-ml-kit/face-detection';
import * as FileSystem from 'expo-file-system';
import { VisionCameraProxy, Frame } from 'react-native-vision-camera';

const visionCameraProxy = VisionCameraProxy.initFrameProcessorPlugin('scanFaces');

export async function detectFaces(photoUri) {
  try {
    const options = {
      enableLandmarks: true,
      enableClassification: true,
      enableTracking: false,
    };
    
    const faceDetector = FaceDetector(options);
    const result = await faceDetector.process(photoUri);
    
    return result;
  } catch (error) {
    console.error('Face detection error:', error);
    throw error;
  }
}

export async function compareFaces(registeredFacePath, detectedFace) {
  // ƒê√¢y l√† logic ƒë∆°n gi·∫£n, c√≥ th·ªÉ n√¢ng c·∫•p sau
  // So s√°nh c√°c ƒë·∫∑c tr∆∞ng khu√¥n m·∫∑t
  
  if (!detectedFace || detectedFace.length === 0) {
    return { match: false, confidence: 0 };
  }
  
  // TODO: Implement actual face comparison using ML Kit or custom model
  // For now, return success if face is detected
  return {
    match: true,
    confidence: 0.85
  };
}
```

### 2. C·∫≠p nh·∫≠t checkin.js

Th√™m face detection v√†o flow ch·∫•m c√¥ng:

```javascript
import { detectFaces, compareFaces } from '../services/faceDetectionService';

// Trong handlePictureTaken:
const handlePictureTaken = async (photo) => {
  setIsCameraOpen(false);
  
  if (!photo || !photo.uri) {
    Alert.alert('L·ªói', 'Kh√¥ng th·ªÉ l·∫•y ƒë∆∞·ª£c ·∫£nh.');
    return;
  }

  try {
    // 1. Detect faces trong ·∫£nh
    console.log('üîç Detecting faces...');
    const faces = await detectFaces(photo.uri);
    
    if (!faces || faces.length === 0) {
      Alert.alert(
        'Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t',
        'Vui l√≤ng ƒë∆∞a khu√¥n m·∫∑t v√†o khung v√† ch·ª•p l·∫°i.',
        [{ text: 'OK', onPress: () => setIsCameraOpen(true) }]
      );
      return;
    }
    
    if (faces.length > 1) {
      Alert.alert(
        'Ph√°t hi·ªán nhi·ªÅu khu√¥n m·∫∑t',
        'Vui l√≤ng ch·ª•p ch·ªâ m·ªôt ng∆∞·ªùi.',
        [{ text: 'OK', onPress: () => setIsCameraOpen(true) }]
      );
      return;
    }
    
    // 2. So s√°nh v·ªõi khu√¥n m·∫∑t ƒë√£ ƒëƒÉng k√Ω
    console.log('üîê Comparing faces...');
    const comparisonResult = await compareFaces(
      user.facePhotoPath, // C·∫ßn l∆∞u path ·∫£nh ƒëƒÉng k√Ω
      faces[0]
    );
    
    if (!comparisonResult.match || comparisonResult.confidence < 0.7) {
      Alert.alert(
        'Khu√¥n m·∫∑t kh√¥ng kh·ªõp',
        'Khu√¥n m·∫∑t kh√¥ng kh·ªõp v·ªõi t√†i kho·∫£n ƒë√£ ƒëƒÉng k√Ω.',
        [{ text: 'OK', onPress: () => setIsCameraOpen(true) }]
      );
      return;
    }
    
    console.log(`‚úÖ Face match! Confidence: ${comparisonResult.confidence}`);
    
    // 3. Ti·∫øp t·ª•c process check-in nh∆∞ b√¨nh th∆∞·ªùng
    setCapturedImage(photo.uri);
    // ... rest of check-in logic
    
  } catch (error) {
    console.error('Face detection error:', error);
    Alert.alert('L·ªói', 'Kh√¥ng th·ªÉ x√°c th·ª±c khu√¥n m·∫∑t.');
  }
};
```

## üöÄ Ch·∫°y app

### Development mode v·ªõi Custom Dev Client:
```bash
# Start development server
npm start -- --dev-client

# Ho·∫∑c n·∫øu ƒë√£ build xong
eas build:run -p android
eas build:run -p ios
```

### Development mode local:
```bash
npx expo run:android --device
npx expo run:ios --device
```

## üîç Testing

1. **Test face detection**: Ch·ª•p ·∫£nh c√≥ khu√¥n m·∫∑t v√† kh√¥ng c√≥ khu√¥n m·∫∑t
2. **Test face matching**: So s√°nh v·ªõi ·∫£nh ƒë√£ ƒëƒÉng k√Ω
3. **Test check-in flow**: Ho√†n ch·ªânh flow ch·∫•m c√¥ng v·ªõi face recognition

## ‚ö†Ô∏è L∆∞u √Ω quan tr·ªçng

1. **Custom Dev Client** kh√°c v·ªõi Expo Go:
   - Kh√¥ng th·ªÉ scan QR code
   - Ph·∫£i build app tr∆∞·ªõc khi ch·∫°y
   - C√≥ th·ªÉ s·ª≠ d·ª•ng native modules

2. **Performance**:
   - Face detection kh√° n·∫∑ng
   - N√™n optimize ·∫£nh tr∆∞·ªõc khi detect
   - C√≥ th·ªÉ cache k·∫øt qu·∫£

3. **B·∫£o m·∫≠t**:
   - Kh√¥ng l∆∞u tr·ªØ ·∫£nh khu√¥n m·∫∑t d·∫°ng raw
   - N√™n hash/encode face features
   - Encrypt data tr∆∞·ªõc khi g·ª≠i server

## üìö T√†i li·ªáu tham kh·∫£o

- [Expo Custom Dev Client](https://docs.expo.dev/development/introduction/)
- [React Native Vision Camera](https://github.com/mrousavy/react-native-vision-camera)
- [ML Kit Face Detection](https://developers.google.com/ml-kit/vision/face-detection)
- [EAS Build](https://docs.expo.dev/build/introduction/)

## üéØ Roadmap n√¢ng c·∫•p

1. **Advanced Face Recognition**:
   - S·ª≠ d·ª•ng TensorFlow Lite
   - Custom ML model cho face recognition
   - Face embedding comparison

2. **Liveness Detection**:
   - Ph√°t hi·ªán khu√¥n m·∫∑t gi·∫£ (spoofing)
   - Y√™u c·∫ßu ng∆∞·ªùi d√πng c·ª≠ ƒë·ªông
   - Detect 3D vs 2D

3. **Offline Support**:
   - Ch·∫°y face detection offline
   - Cache ML models
   - Sync khi online
